{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project #1: Predicting logic errors of digital circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach & Reasoning:\n",
    "\n",
    "Provided data is presented as an extensionless file  \n",
    "File must first be read into python in order to parse it to the appropriate data structure  \n",
    "Once data is in the proper format we will analyze it's shape according to:   \n",
    "\n",
    "X*theta = Y, where X is our input data and Y is our output\n",
    "\n",
    "X our input data will always be 32 bits long  \n",
    "\n",
    "Input data shape: 15000,32  \n",
    "  \n",
    "\n",
    "Y = each of the 32 column \n",
    "\n",
    "Output data label shape: 15000,1\n",
    "\n",
    "**Based on this information 32 individual models must be created in order to predict all 32 bits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preparing Data\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function converts any file seperated by newlines to a numpy array\n",
    "# accounts for any whitespace in the file\n",
    "def file2Array(fileName, datatype):\n",
    "    fileData = [line.rstrip('\\n') for line in open(fileName)]\n",
    "    \n",
    "    dataList = [] \n",
    "    for i in range(len(fileData)):\n",
    "        temp = \"\".join(fileData[i].split())\n",
    "        dataList.append(temp)\n",
    "    #print(dataList[0])\n",
    "\n",
    "    # map() can listify the list of strings individually \n",
    "    dataList = list(map(list, dataList)) \n",
    "    #print(dataList[0]) \n",
    "\n",
    "    dataArray = np.asarray(dataList, dtype=datatype)\n",
    "    #print(dataArray.shape)\n",
    "    \n",
    "    return dataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare numpy arrays for machine learning model\n",
    "trainingData  = file2Array('training_data' ,int)\n",
    "trainingLabel = file2Array('training_label',int)\n",
    "testingData   = file2Array('testing_data'  ,int)\n",
    "testingLabel  = file2Array('testing_label' ,int) \n",
    "\n",
    "# count the number of feature in the given label file\n",
    "featureCount    = np.size(trainingLabel,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Build Machine Learning Model using scikit-learn\n",
    "### 4 Step Process [I,M,T,P]\n",
    "1. **Import**\n",
    "2. **Make**\n",
    "3. **Train**\n",
    "4. **Predict**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example workflow:\n",
    "### Step 1: [I]mport Model\n",
    "\n",
    "```from sklearn import tree ```\n",
    "### Step 2: [M]ake Model\n",
    "```clf = tree.DecisionTreeClassifier()```\n",
    "### Step 3: [T]rain Model\n",
    "``` clf.fit(trainingData,trainingLabel) ```\n",
    "### Step 4: [P]redict with Model\n",
    "```predictions = clf.predict(testingData)```\n",
    "### Gather Metrics\n",
    "```aScore = accuracy_score(testingLabelCol, predictions)\n",
    "pScore = precision_score(testingLabelCol, predictions)\n",
    "rScore = recall_score(testingLabelCol, predictions)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Model\n",
    "from sklearn import tree\n",
    "# import desired metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results: \n",
      "0 0.9972 0.9970259425391778 0.9972\n",
      "1 0.994 0.9939054417945009 0.994\n",
      "2 0.98728 0.9870550926406854 0.98728\n",
      "3 0.9709 0.969866998481936 0.9709\n",
      "4 0.9501 0.9488056865711675 0.9501\n",
      "5 0.91538 0.9121859462365308 0.91538\n",
      "6 0.90628 0.9030547051781299 0.90628\n",
      "7 0.87442 0.8721271067889457 0.87442\n",
      "8 0.88076 0.8772736805620921 0.88076\n",
      "9 0.84832 0.8471847392116618 0.84832\n",
      "10 0.84798 0.8439515543170978 0.84798\n",
      "11 0.81954 0.8152767039308854 0.81954\n",
      "12 0.81392 0.8091706076354079 0.81392\n",
      "13 0.79466 0.7894819712011323 0.79466\n",
      "14 0.77596 0.7702700192934141 0.77596\n",
      "15 0.77918 0.7727125635343316 0.77918\n",
      "16 0.7648 0.7593233227786733 0.7648\n",
      "17 0.80242 0.7974104621772419 0.80242\n",
      "18 0.81712 0.8135441432586242 0.81712\n",
      "19 0.83072 0.8278640502206966 0.83072\n",
      "20 0.86442 0.8628015196970772 0.86442\n",
      "21 0.856 0.852925655846768 0.856\n",
      "22 0.9051 0.90382754394975 0.9051\n",
      "23 0.9003 0.8992790108684932 0.9003\n",
      "24 0.94796 0.9475434118232896 0.94796\n",
      "25 0.97148 0.9713853887191384 0.97148\n",
      "26 0.98314 0.983154116218633 0.98314\n",
      "27 0.98696 0.9870785780987964 0.98696\n",
      "28 1.0 1.0 1.0\n",
      "29 1.0 1.0 1.0\n",
      "30 1.0 1.0 1.0\n",
      "31 1.0 1.0 1.0\n",
      "\n",
      "\n",
      "Mean Accuracy:  0.8995718749999999\n",
      "Mean Precision:  0.8973589363616962\n",
      "Mean Recall:  0.8995718749999999\n"
     ]
    }
   ],
   "source": [
    "aScoreAvg,pScoreAvg,rScoreAvg = 0,0,0\n",
    "aScoreTotal,pScoreTotal,rScoreTotal = 0,0,0\n",
    "# Make Model\n",
    "clf = tree.DecisionTreeClassifier(max_depth=12)\n",
    "\n",
    "print(\"Decision Tree Results: \")\n",
    "\n",
    "# Train model for all 32 features \n",
    "\n",
    "for i in range(featureCount):\n",
    "\n",
    "    # extract column\n",
    "    trainingLabelCol = (trainingLabel[:, [i]]).ravel()\n",
    "    testingLabelCol = (testingLabel[:, [i]]).ravel()\n",
    "    #print(trainingLabel) #debug\n",
    "    #print(trainingData)  #debug\n",
    "    \n",
    "    if((len(np.unique(trainingLabelCol)) and len(np.unique(testingLabelCol))) == 1):\n",
    "        aScore = 1.0\n",
    "        pScore = 1.0\n",
    "        rScore = 1.0\n",
    "        \n",
    "        aScoreTotal += aScore\n",
    "        pScoreTotal += pScore\n",
    "        rScoreTotal += rScore\n",
    "        #print(i,score,np.unique(trainingLabelCol),np.unique(testingLabelCol)) #print unique elements\n",
    "        print(i,aScore,pScore,rScore)\n",
    "        continue\n",
    "    \n",
    "    # fit model\n",
    "    clf.fit(trainingData,trainingLabelCol)\n",
    "    \n",
    "    # generate all predictions\n",
    "    predictions = clf.predict(testingData)\n",
    "    \n",
    "    # obtain metrics (accuracy, precision, recall)\n",
    "    aScore = accuracy_score(testingLabelCol, predictions)\n",
    "    pScore = precision_score(testingLabelCol, predictions, average='weighted') \n",
    "    rScore = recall_score(testingLabelCol, predictions, average='weighted')\n",
    "    \n",
    "    # Sum all scores to average at the end\n",
    "    aScoreTotal += aScore\n",
    "    pScoreTotal += pScore\n",
    "    rScoreTotal += rScore\n",
    "    \n",
    "    #print(i,aScore,pScore,rScore,np.unique(trainingLabelCol),np.unique(testingLabelCol)) #extended print func\n",
    "    print(i,aScore,pScore,rScore)\n",
    "\n",
    "# also works also dont forget the rest of the metrics jiao wants\n",
    "#accuracy_score((testingLabel[:, [4]]).ravel(), predictions)\n",
    "aScoreAvg = aScoreTotal/featureCount\n",
    "pScoreAvg = pScoreTotal/featureCount\n",
    "rScoreAvg = rScoreTotal/featureCount\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Mean Accuracy: \", aScoreAvg)\n",
    "print(\"Mean Precision: \", pScoreAvg)\n",
    "print(\"Mean Recall: \", rScoreAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 0:00:23.499191\n"
     ]
    }
   ],
   "source": [
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary:\n",
    "\n",
    "Decision tree model was used since it had the best accuracy compared to: \n",
    "* Neural Networks\n",
    "* SVM\n",
    "* Naive Bayes\n",
    "* Random Forests\n",
    "\n",
    "One issue was encountered in col[32] all results were 0 which means only one class existed and caused the model to error out, this was corrected by detecting the amount of unique values in the columns if only 1 was detected.   It would mean that the prediction would always be true unless proven otherwise. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
